{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4Zr8oCW8lSin",
        "outputId": "121315a7-26a9-4956-b606-77e0ba042c53"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2023-05-04 04:25:40--  https://raw.githubusercontent.com/AbhiDhariwal/Hindi-NER/master/CoNLL2Spacy.py\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.110.133, 185.199.109.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 1128 (1.1K) [text/plain]\n",
            "Saving to: ‘CoNLL2Spacy.py’\n",
            "\n",
            "\rCoNLL2Spacy.py        0%[                    ]       0  --.-KB/s               \rCoNLL2Spacy.py      100%[===================>]   1.10K  --.-KB/s    in 0s      \n",
            "\n",
            "2023-05-04 04:25:40 (76.5 MB/s) - ‘CoNLL2Spacy.py’ saved [1128/1128]\n",
            "\n"
          ]
        }
      ],
      "source": [
        "!wget https://raw.githubusercontent.com/AbhiDhariwal/Hindi-NER/master/CoNLL2Spacy.py"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from CoNLL2Spacy import *"
      ],
      "metadata": {
        "id": "xyjzlv-tlVVb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "file = open(\"/content/nervalweather.txt\", \"r\",encoding = \"utf-8\") \n",
        "valList = []\n",
        "for line in file:\n",
        "    valList.append(line[:-1])\n",
        "valList[:15]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "s-JCvQRJlVYL",
        "outputId": "9ca913fe-cc4b-4d99-a003-5b7bb2f8165c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['आज U-date',\n",
              " 'मौसम O',\n",
              " 'कैसा O',\n",
              " 'है O',\n",
              " '',\n",
              " 'क्या O',\n",
              " 'हरिद्वार U-location',\n",
              " 'में O',\n",
              " 'बहुत O',\n",
              " 'ठंड U-weather_type',\n",
              " 'है O',\n",
              " 'अभी U-date',\n",
              " '',\n",
              " 'आज U-date',\n",
              " 'इतनी O']"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "TEST_DATA = conll2spacy(valList)"
      ],
      "metadata": {
        "id": "2OJv4HHvlVaz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "file = open(\"/content/nervalweather.txt\", \"r\",encoding = \"utf-8\") \n",
        "trainList = []\n",
        "for line in file:\n",
        "    trainList.append(line[:-1])\n",
        "trainList[:15]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gneu7CFelVdM",
        "outputId": "e5b8fb24-3470-4e92-8839-779e9f17f5bd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['आज U-date',\n",
              " 'मौसम O',\n",
              " 'कैसा O',\n",
              " 'है O',\n",
              " '',\n",
              " 'क्या O',\n",
              " 'हरिद्वार U-location',\n",
              " 'में O',\n",
              " 'बहुत O',\n",
              " 'ठंड U-weather_type',\n",
              " 'है O',\n",
              " 'अभी U-date',\n",
              " '',\n",
              " 'आज U-date',\n",
              " 'इतनी O']"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "TRAIN_DATA = conll2spacy(trainList)"
      ],
      "metadata": {
        "id": "kKUlqTSqAOGI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import warnings\n",
        "warnings.filterwarnings('ignore')"
      ],
      "metadata": {
        "id": "9h1-xK1jlVfu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!wget https://dl.fbaipublicfiles.com/fasttext/vectors-wiki/wiki.hi.vec"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lEcVSDaVmtP1",
        "outputId": "457ffc7e-0c42-4a3e-dc92-2e0124e38e2e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2023-05-04 04:29:10--  https://dl.fbaipublicfiles.com/fasttext/vectors-wiki/wiki.hi.vec\n",
            "Resolving dl.fbaipublicfiles.com (dl.fbaipublicfiles.com)... 13.249.39.89, 13.249.39.25, 13.249.39.6, ...\n",
            "Connecting to dl.fbaipublicfiles.com (dl.fbaipublicfiles.com)|13.249.39.89|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 416644179 (397M) [binary/octet-stream]\n",
            "Saving to: ‘wiki.hi.vec’\n",
            "\n",
            "wiki.hi.vec         100%[===================>] 397.34M  30.7MB/s    in 12s     \n",
            "\n",
            "2023-05-04 04:29:23 (31.8 MB/s) - ‘wiki.hi.vec’ saved [416644179/416644179]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import spacy\n",
        "import numpy\n",
        "import pickle"
      ],
      "metadata": {
        "id": "NgEoNKVamtVo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "lang = \"hi\"\n",
        "vectors_loc = \"wiki.hi.vec\"\n",
        "nlp = spacy.blank(lang)    \n",
        "with open(vectors_loc, \"rb\") as file_:        \n",
        "    header = file_.readline()        \n",
        "    nr_row, nr_dim = header.split()        \n",
        "    nlp.vocab.reset_vectors(width=int(nr_dim))        \n",
        "    for line in file_:            \n",
        "        line = line.rstrip().decode(\"utf8\")            \n",
        "        pieces = line.rsplit(\" \", int(nr_dim))            \n",
        "        word = pieces[0]            \n",
        "        vector = numpy.asarray([float(v) for v in pieces[1:]], dtype=\"f\")            \n",
        "        nlp.vocab.set_vector(word, vector)  # add the vectors to the vocab   "
      ],
      "metadata": {
        "id": "SkgbapSRmtWj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "text = \"भारी बारिश के कारण आज कार्यालय बंद रहेगा\"    \n",
        "doc = nlp(text)    \n",
        "print(\"similarity btw\",doc[0] , \"and\", doc[3],\" :-\", doc[0].similarity(doc[3]))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pzqB0meZmtX_",
        "outputId": "352a5a6e-2a64-4ff8-f30c-a7c2d7c7228b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "similarity btw भारी and कारण  :- 0.4151364266872406\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -U pip setuptools wheel\n",
        "!pip install -U spacy"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5KXxBcBWnp6W",
        "outputId": "d515dcc3-669a-49d4-d2c6-63324c916d44"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: pip in /usr/local/lib/python3.10/dist-packages (23.0.1)\n",
            "Collecting pip\n",
            "  Downloading pip-23.1.2-py3-none-any.whl (2.1 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.1/2.1 MB\u001b[0m \u001b[31m78.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (67.7.2)\n",
            "Requirement already satisfied: wheel in /usr/local/lib/python3.10/dist-packages (0.40.0)\n",
            "Installing collected packages: pip\n",
            "  Attempting uninstall: pip\n",
            "    Found existing installation: pip 23.0.1\n",
            "    Uninstalling pip-23.0.1:\n",
            "      Successfully uninstalled pip-23.0.1\n",
            "Successfully installed pip-23.1.2\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: spacy in /usr/local/lib/python3.10/dist-packages (3.5.2)\n",
            "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.11 in /usr/local/lib/python3.10/dist-packages (from spacy) (3.0.12)\n",
            "Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from spacy) (1.0.4)\n",
            "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.10/dist-packages (from spacy) (1.0.9)\n",
            "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.10/dist-packages (from spacy) (2.0.7)\n",
            "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.10/dist-packages (from spacy) (3.0.8)\n",
            "Requirement already satisfied: thinc<8.2.0,>=8.1.8 in /usr/local/lib/python3.10/dist-packages (from spacy) (8.1.9)\n",
            "Requirement already satisfied: wasabi<1.2.0,>=0.9.1 in /usr/local/lib/python3.10/dist-packages (from spacy) (1.1.1)\n",
            "Requirement already satisfied: srsly<3.0.0,>=2.4.3 in /usr/local/lib/python3.10/dist-packages (from spacy) (2.4.6)\n",
            "Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in /usr/local/lib/python3.10/dist-packages (from spacy) (2.0.8)\n",
            "Requirement already satisfied: typer<0.8.0,>=0.3.0 in /usr/local/lib/python3.10/dist-packages (from spacy) (0.7.0)\n",
            "Requirement already satisfied: pathy>=0.10.0 in /usr/local/lib/python3.10/dist-packages (from spacy) (0.10.1)\n",
            "Requirement already satisfied: smart-open<7.0.0,>=5.2.1 in /usr/local/lib/python3.10/dist-packages (from spacy) (6.3.0)\n",
            "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /usr/local/lib/python3.10/dist-packages (from spacy) (4.65.0)\n",
            "Requirement already satisfied: numpy>=1.15.0 in /usr/local/lib/python3.10/dist-packages (from spacy) (1.22.4)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from spacy) (2.27.1)\n",
            "Requirement already satisfied: pydantic!=1.8,!=1.8.1,<1.11.0,>=1.7.4 in /usr/local/lib/python3.10/dist-packages (from spacy) (1.10.7)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from spacy) (3.1.2)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from spacy) (67.7.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from spacy) (23.1)\n",
            "Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in /usr/local/lib/python3.10/dist-packages (from spacy) (3.3.0)\n",
            "Requirement already satisfied: typing-extensions>=4.2.0 in /usr/local/lib/python3.10/dist-packages (from pydantic!=1.8,!=1.8.1,<1.11.0,>=1.7.4->spacy) (4.5.0)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (1.26.15)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (2022.12.7)\n",
            "Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (2.0.12)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (3.4)\n",
            "Requirement already satisfied: blis<0.8.0,>=0.7.8 in /usr/local/lib/python3.10/dist-packages (from thinc<8.2.0,>=8.1.8->spacy) (0.7.9)\n",
            "Requirement already satisfied: confection<1.0.0,>=0.0.1 in /usr/local/lib/python3.10/dist-packages (from thinc<8.2.0,>=8.1.8->spacy) (0.0.4)\n",
            "Requirement already satisfied: click<9.0.0,>=7.1.1 in /usr/local/lib/python3.10/dist-packages (from typer<0.8.0,>=0.3.0->spacy) (8.1.3)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->spacy) (2.1.2)\n",
            "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
            "\u001b[0m"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pip install --upgrade spacy"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HglPVIy_zL_P",
        "outputId": "c4522347-7f69-40b7-d864-f29e0e0a3ca3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: spacy in /usr/local/lib/python3.10/dist-packages (3.5.2)\n",
            "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.11 in /usr/local/lib/python3.10/dist-packages (from spacy) (3.0.12)\n",
            "Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from spacy) (1.0.4)\n",
            "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.10/dist-packages (from spacy) (1.0.9)\n",
            "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.10/dist-packages (from spacy) (2.0.7)\n",
            "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.10/dist-packages (from spacy) (3.0.8)\n",
            "Requirement already satisfied: thinc<8.2.0,>=8.1.8 in /usr/local/lib/python3.10/dist-packages (from spacy) (8.1.9)\n",
            "Requirement already satisfied: wasabi<1.2.0,>=0.9.1 in /usr/local/lib/python3.10/dist-packages (from spacy) (1.1.1)\n",
            "Requirement already satisfied: srsly<3.0.0,>=2.4.3 in /usr/local/lib/python3.10/dist-packages (from spacy) (2.4.6)\n",
            "Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in /usr/local/lib/python3.10/dist-packages (from spacy) (2.0.8)\n",
            "Requirement already satisfied: typer<0.8.0,>=0.3.0 in /usr/local/lib/python3.10/dist-packages (from spacy) (0.7.0)\n",
            "Requirement already satisfied: pathy>=0.10.0 in /usr/local/lib/python3.10/dist-packages (from spacy) (0.10.1)\n",
            "Requirement already satisfied: smart-open<7.0.0,>=5.2.1 in /usr/local/lib/python3.10/dist-packages (from spacy) (6.3.0)\n",
            "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /usr/local/lib/python3.10/dist-packages (from spacy) (4.65.0)\n",
            "Requirement already satisfied: numpy>=1.15.0 in /usr/local/lib/python3.10/dist-packages (from spacy) (1.22.4)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from spacy) (2.27.1)\n",
            "Requirement already satisfied: pydantic!=1.8,!=1.8.1,<1.11.0,>=1.7.4 in /usr/local/lib/python3.10/dist-packages (from spacy) (1.10.7)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from spacy) (3.1.2)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from spacy) (67.7.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from spacy) (23.1)\n",
            "Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in /usr/local/lib/python3.10/dist-packages (from spacy) (3.3.0)\n",
            "Requirement already satisfied: typing-extensions>=4.2.0 in /usr/local/lib/python3.10/dist-packages (from pydantic!=1.8,!=1.8.1,<1.11.0,>=1.7.4->spacy) (4.5.0)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (1.26.15)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (2022.12.7)\n",
            "Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (2.0.12)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (3.4)\n",
            "Requirement already satisfied: blis<0.8.0,>=0.7.8 in /usr/local/lib/python3.10/dist-packages (from thinc<8.2.0,>=8.1.8->spacy) (0.7.9)\n",
            "Requirement already satisfied: confection<1.0.0,>=0.0.1 in /usr/local/lib/python3.10/dist-packages (from thinc<8.2.0,>=8.1.8->spacy) (0.0.4)\n",
            "Requirement already satisfied: click<9.0.0,>=7.1.1 in /usr/local/lib/python3.10/dist-packages (from typer<0.8.0,>=0.3.0->spacy) (8.1.3)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->spacy) (2.1.2)\n",
            "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
            "\u001b[0m"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for ent in doc.ents:\n",
        "     print(ent.text,\"|\",ent.label_,\"|\",spacy.explain(ent.label_))"
      ],
      "metadata": {
        "id": "9QfFtWpf4nkQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from spacy import displacy\n",
        "displacy.render(doc,style=\"ent\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "P2q_qUy14pGA",
        "outputId": "b355b2b7-715a-44cf-b827-5a3ff4fc7589"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'<div class=\"entities\" style=\"line-height: 2.5; direction: ltr\">भारी बारिश के कारण आज कार्यालय बंद रहेगा</div>'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import spacy\n",
        "import random \n",
        "\n",
        "from spacy.util import minibatch, compounding\n",
        "\n",
        "from spacy.scorer import Scorer"
      ],
      "metadata": {
        "id": "hjwpMHhUmtaO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def train_spacy(TRAIN_DATA,TEST_DATA,iterations,droprate = 0.5,modelName = \"modelTrained\"):\n",
        "\n",
        "    # loading hindi model and using vector from fasttext\n",
        "    lang = \"hi\"\n",
        "    vectors_loc = \"wiki.hi.vec\"\n",
        "    modiner = spacy.blank(lang)    \n",
        "    with open(vectors_loc, \"rb\") as file_:        \n",
        "        header = file_.readline()        \n",
        "        nr_row, nr_dim = header.split()        \n",
        "        modiner.vocab.reset_vectors(width=int(nr_dim))        \n",
        "        for line in file_:            \n",
        "            line = line.rstrip().decode(\"utf8\")            \n",
        "            pieces = line.rsplit(\" \", int(nr_dim))            \n",
        "            word = pieces[0]            \n",
        "            vector = numpy.asarray([float(v) for v in pieces[1:]], dtype=\"f\")            \n",
        "            modiner.vocab.set_vector(word, vector)  # add the vectors to the vocab    \n",
        "\n",
        "#     modiner = spacy.blank('en')  # create blank Language class\n",
        "    \n",
        "    # create the built-in pipeline components and add them to the pipeline\n",
        "    # nlp.create_pipe works for built-ins that are registered with spaCy\n",
        "    if 'ner' not in modiner.pipe_names:\n",
        "        ner = modiner.create_pipe('ner')\n",
        "        modiner.add_pipe(ner, last=True)\n",
        "     \n",
        "    # setting up f1score\n",
        "    f1score = 0.0000\n",
        "\n",
        "    \n",
        "    # add labels that will be involved in training \n",
        "    for _, annotations in TRAIN_DATA:\n",
        "         for ent in annotations.get('entities'):\n",
        "            ner.add_label(ent[2])\n",
        "    other_pipes = [pipe for pipe in modiner.pipe_names if pipe != 'ner']\n",
        "    with modiner.disable_pipes(*other_pipes):  # only train NER\n",
        "        optimizer = modiner.begin_training()\n",
        "        \n",
        "        # --Iterations Starts--\n",
        "        for itn in range(iterations):\n",
        "            print(\"Starting iteration \" + str(itn))\n",
        "            #--Shuffling Traning Data--\n",
        "            random.shuffle(TRAIN_DATA)\n",
        "            losses = {}\n",
        "            \n",
        "                      \n",
        "                    \n",
        "            # batch Traning For better Training and Learning of model\n",
        "            batches = minibatch(TRAIN_DATA, size=compounding(2.0, 16.0, 1.01))\n",
        "            for batch in batches:\n",
        "                texts, annotations = zip(*batch)\n",
        "                modiner.update(\n",
        "                    texts,  # batch of texts\n",
        "                    annotations,  # batch of annotations\n",
        "                    drop=droprate,  # dropout - make it harder to memorise data\n",
        "                    losses=losses,\n",
        "                )\n",
        "            print(losses)\n",
        "            \n",
        "            \n",
        "            # Evaluating the Current Model Score on test data\n",
        "            results = evaluate(modiner, TEST_DATA)\n",
        "            print(\"Current Score :-\",results[\"ents_f\"], \"Precision  :-\",results[\"ents_p\"], \"Recall  :-\",results[\"ents_r\"])\n",
        "            \n",
        "\n",
        "            \n",
        "            # loading previous best saved model in start of traning \n",
        "            if f1score == 0.00:\n",
        "                try:                    \n",
        "                    pnlp = spacy.load(modelName)\n",
        "                    result = evaluate(pnlp, TEST_DATA) # calling evaluate function \n",
        "                    f1score = result[\"ents_f\"]\n",
        "                except:\n",
        "                    print(\"Previous Model not found\")\n",
        "                    \n",
        "            print(\"Best Sccore :- \",f1score)\n",
        "            print(\"------------------------------------\")\n",
        "            # finding out the best score\n",
        "            if f1score < results[\"ents_f\"]:\n",
        "                f1score = results[\"ents_f\"]\n",
        "                \n",
        "                # Save our trained Model if the score if grater than best score else no change in previous model\n",
        "                modiner.to_disk(modelName)\n",
        "                \n",
        "    print(\"-----Best Model is Saved-----\")"
      ],
      "metadata": {
        "id": "i9gzFdFXmtbt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def evaluate(ner_model, examples):\n",
        "    scorer = Scorer()\n",
        "     \n",
        "    #loading tags for each input and Evaluating them\n",
        "    for input_, annotations in examples:\n",
        "        tags = []\n",
        "        # loading text\n",
        "        doc_gold_text = ner_model.make_doc(input_)\n",
        "        \n",
        "        #loading all tags for that text\n",
        "        for ent in annotations.get('entities'):\n",
        "            tags.append(ent)\n",
        "            \n",
        "        # Evaluating the tags    \n",
        "        gold = GoldParse(doc_gold_text, entities=tags)\n",
        "        pred_value = ner_model(input_)\n",
        "        scorer.score(pred_value, gold)\n",
        "        \n",
        "        \n",
        "    return scorer.scores"
      ],
      "metadata": {
        "id": "nem9XFCvmtdU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def loadNERModel(modelName = \"modelTrained\"):\n",
        "    nlp = spacy.load(modelName)\n",
        "    return nlp"
      ],
      "metadata": {
        "id": "Gb3B8UDG02aM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def score(model,TEST_DATA):\n",
        "    result = evaluate(model, TEST_DATA) # calling evaluate function \n",
        "    f1score = result[\"ents_f\"]\n",
        "    precision = result[\"ents_p\"]\n",
        "    recall = result[\"ents_r\"]\n",
        "    print(\"F1 score of Model is :-\",f1score)\n",
        "    print(\"Precision of Model is :-\",precision)\n",
        "    print(\"Recall of Model is :-\",recall)"
      ],
      "metadata": {
        "id": "EgTfeoWx05Ik"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from spacy.language import Language\n",
        "from spacy.pipeline import EntityRecognizer\n",
        "\n",
        "@Language.component('custom_ner')\n",
        "def custom_ner_component(doc):\n",
        "    # Your custom NER logic here\n",
        "    return doc\n",
        "\n",
        "# Add the component to the pipeline\n",
        "nlp.add_pipe('custom_ner')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e9-_csjSC8Tl",
        "outputId": "deaa6900-d0a8-448b-f04c-57c88a8bae52"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<function __main__.custom_ner_component(doc)>"
            ]
          },
          "metadata": {},
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def train_spacy(TRAIN_DATA, TEST_DATA, iterations, droprate=0.5, modelName=\"hindiNER\"):\n",
        "    nlp = spacy.blank('hi')\n",
        "    print(\"Created blank Hindi model\")\n",
        "    if 'ner' not in nlp.pipe_names:\n",
        "        ner = nlp.create_pipe('ner')\n",
        "        nlp.add_pipe('ner', last=True)\n",
        "        print(\"Added NER component to pipeline\")\n",
        "    else:\n",
        "        ner = nlp.get_pipe('ner')\n",
        "        \n",
        "    # Adding labels to the ner\n",
        "    for _, annotations in TRAIN_DATA:\n",
        "         for ent in annotations.get('entities'):\n",
        "            ner.add_label(ent[2])\n",
        "    \n",
        "    other_pipes = [pipe for pipe in nlp.pipe_names if pipe != 'ner']\n",
        "    \n",
        "    with nlp.disable_pipes(*other_pipes):\n",
        "        optimizer = nlp.begin_training()\n",
        "        dropout = droprate\n",
        "        for itn in range(iterations):\n",
        "            random.shuffle(TRAIN_DATA)\n",
        "            losses = {}\n",
        "            batches = minibatch(TRAIN_DATA, size=compounding(4.0, 32.0, 1.001))\n",
        "            for batch in batches:\n",
        "                texts, annotations = zip(*batch)\n",
        "                nlp.update(texts, annotations, sgd=optimizer, drop=dropout, losses=losses)\n",
        "            print(\"Losses at iteration \", itn, \" - \", losses)\n",
        "            \n",
        "    # Testing the model\n",
        "    for text, _ in TEST_DATA:\n",
        "        doc = nlp(text)\n",
        "        print(\"Entities\", [(ent.text, ent.label_) for ent in doc.ents])\n",
        "        \n",
        "    # Save the model\n",
        "    output_dir = Path('contentnervalweather.txt')\n",
        "    if not output_dir.exists():\n",
        "        output_dir.mkdir()\n",
        "    nlp.to_disk(output_dir / modelName)\n",
        "    print(\"Model saved to \", output_dir / modelName)"
      ],
      "metadata": {
        "id": "f2lVK6JY07zU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "4w2AxiLdDsZd"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}